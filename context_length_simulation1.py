# This code simulates multiple users infering the model in a chat format, keeping the chat history as context.
# As context increases, generation speed decreases. The more users infering the model at the same time, the larger the generation speed decrease.
# "gaunernst/gemma-3-27b-it-int4-awq" allowed a context length of around ~27k-28k tokens.
# Simulation results are available in "eval/context_length_simulation/gaunernst-gemma-3-27b-it-int4-awq"

import subprocess
import requests
import time
import json
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from transformers import AutoTokenizer
from typing import Dict
import torch


torch.cuda.empty_cache()

num_users = 5
max_concurrent = 5

tokens = []
times = []


# Load tokenizer
model_id = "gaunernst/gemma-3-27b-it-qat-autoawq"
tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)


model_id_clean = model_id.replace("/", "-")
file_name = f"{model_id_clean}_{num_users}_users"

# ====== MEMORY STORE FOR CHAT HISTORIES ======
conversations: Dict[str, list] = {}

DEFAULT_SYSTEM_PROMPT = {
    "role": "system",
    "content": [{"type": "text", "text": "תענה בבקשה על שאלות המשתמש בשפה העברית."}]
}


# Initialize a new session in conversation history if doesn't exists
def get_or_create_session(session_id: str) -> str:
    if session_id not in conversations:
        conversations[session_id] = {"messages": [DEFAULT_SYSTEM_PROMPT]}
    return session_id


def stream_chat(prompts, i):
    url = "http://localhost:8090/stream"
    headers = {"Content-Type": "application/json"}

    session_id = get_or_create_session(i)

    count = 0

    for prompt in prompts:
        time.sleep(1)
        count += 1
        total_context_length = 0
        
        # Save user's prompt in conversation history  
        conversations[session_id]["messages"].append({"role": "user", "content": [{"type": "text", "text": prompt}]})
    
        response = ""
        toks = 0
        print(f"\n######################### User {i}, Prompt {count}:#########################\n", end='', flush=True)

        # Start counting time for the current prompt
        start_time = time.time()
        
        with requests.post(url, headers=headers, json=conversations[session_id], stream=True) as r:
                for line in r.iter_lines():
                    if line and line.startswith(b"data:"):
                        try:
                            chunk = json.loads(line.lstrip(b"data: ").decode("utf-8"))
                            print(f"User {i} Prompt {count}: ", chunk['choices'][0]['delta'].get('content', ''), "\n", end='', flush=True)
                            # print(chunk['choices'][0]['delta'].get('content', ''), end='', flush=True)
                            response += chunk['choices'][0]['delta'].get('content', '')
    
                        except json.JSONDecodeError:
                            continue
    
        # Save assistant's response in conversation history    
        conversations[session_id]["messages"].append({"role": "assistant", "content": [{"type": "text", "text": response}]})
    
        # Duration of current response                    
        end_time = time.time()
        duration = end_time - start_time
        times.append(duration)

        # Tokens count for current response
        toks = len(tokenizer.encode(response))
        tokens.append(toks)

        # Conversation histort context length
        total_context_length = len(tokenizer.encode(str(conversations[session_id])))

        with open(f"/workspace/{file_name}.txt", "a") as f:
            f.write(f"\n**User {i} Prompt {count}:** duration: {duration}, T/s: {str(toks/duration)} total context length: {total_context_length} \n")
    


    print(f"User {i} finished in {duration:.2f} seconds, {toks/duration} T/s, total context length: {total_context_length} \n", end='', flush=True)

    # with open(f"/workspace/User{i}.txt", "w") as f:
    #     f.write(f"\n{response} \n")
    #     f.write(f"⏱️ Took {duration:.2f} seconds \n")
    #     f.write(f"Number of tokens: {str(toks)} \n")
    #     f.write(f"T/s: {str(toks/duration)}")


def plot_durations(times, tokens, filename1=f"/workspace/{file_name}.png", filename2=f"/workspace/{file_name}_speed.png"):
    import matplotlib.pyplot as plt
    import numpy as np
    x_labels = [f"User {i}" for i in range(len(times))]  

    plt.bar(x_labels, times)
    plt.xlabel("User")
    plt.ylabel("Time (seconds) to output")
    plt.title("Generation Duration for {num_users} Users, {max_concurrent} Simultaneously")
    plt.savefig(filename1)
    print(f"Average duration for {num_users} users, {max_concurrent} simultaneously:: {np.mean(times)}")

    rates = [t / s for t, s in zip(tokens, times)]
    plt.bar(x_labels, rates)
    plt.xlabel("User")
    plt.ylabel("t/s")
    plt.title(f"Generation Speed for {num_users} Users, {max_concurrent} Simultaneously")
    plt.savefig(filename2)
    print(f"Average T/s for {num_users} users, {max_concurrent} simultaneously: {np.mean(tokens)/np.mean(times)}")




# Entry point when run from terminal
if __name__ == "__main__":

    # session_id = 1
    prompt1 = """  תסכם בבקשה את הכתבה הבאה:

ברשת חושדים: זו הדרך המוזרה שבה טראמפ באמת חישב את המכסים שלו
הנוסחה המקורית שבה חושבו לכאורה המכסים שהטיל טראמפ הפתיעה את הכלכלנים שלא מבינים את ההיגיון שבה • כעת טוענים ברשת כי הנוסחה בכלל לא חושבה - אלא התקבלה מצ'טבוט חכם בסגנון chatGPT או גרוק של אילון מאסק • ההוכחה: זו התשובה שהם הציעו כשביקשו מהם "דרך קלה" לפתור גרעונות סחר • חתן פרס נובל הכלכלן פול קרוגמן: "סקיינט יכולה להסתפק בלתת עצות גרועות על מכסים"

המכסים שהטיל טראמפ על שותפות הסחר של ארה"ב הכניסו את הכלכלה העולמית להלם. מעבר לשאלה מה עושים עכשיו, רבים העלו גבה לגבי האופן שבו חושב גובה המכס הספציפי שהוטל על כל מדינה ומדינה. תיאוריה שרצה ברשת בימים שחלפו שמאז "יום השחרור" של טראמפ מעלה סברה מעניינת - הסיבה שכלכלנים מתקשים להבין את ההיגיון מאחורי המספרים היא שאין היגיון: הם יוצרו על ידי צ'טבוט בינה מלאכותית כמו ChatGPT או גרוק של אילון מאסק.
כשטראמפ הציג את מדיניות הסחר החדשה הוא נופף בשלט קרטון גדול עם הכותרת "מכסים הדדיים". הנשיא הכריז על מכס בסיסי של 10% על כל היבוא לארה"ב, כולל מאיים לא מיושבים, בנוסף לשיעורים גבוהים במיוחד על מדינות מסוימות. כך, על סין הוטל מכס נוסף של 34%, על האיחוד האירופי 20% ועל ויטנאם 46%.
הכלכלן ג'יימס סורוביאקי מצא שניתן לשחזר את המספרים של הבית הלבן באמצעות נוסחה פשוטה: לקחת את הגירעון המסחרי של ארה"ב מול מדינה מסוימת ולחלק אותו בסך היצוא של אותה מדינה לארה"ב. אם מחלקים את התוצאה בשתיים, מקבלים מספר שדומה מאד לאותו "מכס הדדי מופחת" של טראמפ. בבית הלבן הכחישו את ההאשמות הללו וטענו כי פיתחו נוסחה משלהם, אך לפי דיווחים זו בסך הכל גירסה מפונפנת של החישוב של סורוביאקי.
על ישראל הוטל מכס בשיעור של 17% - מורכב מ-10% בסיסי ו-7% ייעודי. לפי בכירים באוצר, החישוב נעשה בדיוק לפי הנוסחה המדוברת: הממשל האמריקאי לקח את הגירעון המסחרי של ארה"ב מול ישראל (כ-7 מיליארד דולר) וחילק אותו בסך הייצוא של ישראל לארה"ב (כ-20 מיליארד דולר). התוצאה היא בערך 33%. הממשל האמריקני חילק את התוצאה הזו בשתיים, וכך הגיע למכס של כ-17%.
סורוביאקי כינה את הגישה הזו "שטות מוחלטת". אבל מה שהפתיע רבים היה הגילוי שמספר צ'טבוטים מציעים בדיוק את אותה נוסחה כאשר שואלים אותם על דרך קלה לפתור גירעונות סחר.
דימיון מפתיע לתשובות הבוטים
אתר הטכנולוגיה ה-Verge דיווח כי מספר משתמשים ברשת החברתית אקס (טוויטר לשעבר) גילו שאם שואלים את הצ'טבוטים על "דרך קלה" לפתור גירעונות סחר ולשים את ארה"ב על "מגרש משחקים שווה" - הם מציעים את נוסחת "הגירעון חלקי היצוא" באופן עקבי ומפתיע.
ב-Verge בדקו את הטענות: הם שאלו ארבע מערכות בינה מלאכותית מובילות - ChatGPT, ג'מיני, קלוד וגרוק - כיצד לחשב מכסים שיאזנו את הגירעון המסחרי של ארה"ב. כל ארבע המערכות הציעו את אותה נוסחה בסיסית: לקחת את הגירעון המסחרי ולחלק אותו בסך היצוא.
לפי ה-Verge ישנם הבדלים קטנים בין התשובות. גרוק וקלוד הציעו במפורש לחלק את התוצאה בשתיים כדי ליצור מה שגרוק כינה תוצאה "סבירה" - בדיוק כמו רעיון ה"הנחה" של טראמפ. כששואלים על מכס בסיסי של 10%, המערכות גם חלוקות בשאלה האם יש להוסיף אותו לשיעור המכס הכולל או לא.
"סקיינט לא צריכה לפתוח מלחמה"
פרשן הניו יורק טיימס עזרא קליין העלה את התיאוריה על שימוש בצ'טבוט לחישוב המכסים בראיון שערך בפודקאסט שלו עם הכלכלן חתן פרס נובל פרופ' פול קרוגמן. קליין ציין שאם שואלים את תוכנות הבינה המלאכותית המובילות כמו ChatGPT, ג'מיני וקלוד איך לחשב מכסים על מדינות אחרות, הן מציעות בדיוק את אותו חישוב כמו זה שהציג טראמפ.
קרוגמן הגיב בהומור: "סקיינט לא צריכה לפתוח במלחמה גרעינית. מספיק שתיתן עצות גרועות למכסים". הוא הוסיף שאין אף מאמר כלכלי מקצועי שממליץ על חישוב כזה. "זה פשוט לא משהו שהיית ממליץ עליו אם אתה מבין משהו על איך סחר עובד", הסביר.
לדבריו, הצ'טבוטים מציגים מידע שמצאו ברשת בלי יכולת אמיתית להבחין בין מה שהגיוני למה שלא, וזו בדיוק הסיבה שהמלצה כזו "היא יותר סיפור אזהרה על בינה מלאכותית מאשר משהו על כלכלה".
אפילו הצ'טבוטים הזהירו
ה-Verge דיווח שהצ'טבוטים אמנם הציעו את הנוסחה הפשוטה, אך חלקם גם הוסיפו אזהרות שונות. ג'מיני, למשל, היה הנחרץ ביותר והציג עמוד שלם של הסברים לפיהם מדובר בגישה פשטנית שעתידה להיכשל: "בעוד שחישוב זה מציע דרך פשוטה לכאורה להתמודד עם גירעונות סחר דו-צדדיים, ההשלכות הכלכליות בעולם האמיתי מורכבות הרבה יותר ועלולות להוביל לתוצאות שליליות משמעותיות", הזהיר הצ'טבוט.
ג'מיני אף הוסיף ש"כלכלנים רבים טוענים שמכסים אינם כלי יעיל לאיזון גירעונות סחר" - אזהרה שנראה כי נעלמה מעיני מקבלי ההחלטות.

יותר מ-5 טריליון דולר התאדו
 
עבור בורסות וול סטריט השבוע שעבר היה השבוע הגרוע ביותר שלהן מאז משבר הקורונה. מדד S&P 500 איבד 9.1% מערכו במהלך השבוע, לאחר שצנח ב-6% ביום שישי ו-4.8% ביום חמישי. הירידות החדות לאחר שטראמפ חשף את גובה המכסים, נמחקו כ-5.4 טריליון דולר משווי השוק של החברות במדד ה-S&P 500.
מדד הדאו ג'ונס צנח ביום שישי ב-5.5% ואיבד 2,231 נקודות ביום אחד - הפעם הראשונה בהיסטוריה שהמדד מאבד יותר מ-1,500 נקודות ביומיים רצופים. מדד הנאסד"ק מוטה מניות הטכנולוגיה צנח ביותר מ-20% מאז השיא שרשם בדצמבר - שיעור שמכונה כניסה לשוק דובי, המתאר ירידה חדה ומתמשכת.
המניות שנפגעות במיוחד
את הירידות בבורסה מובילה חברת השבבים טאוואר, שצונחת בקרוב ל-12%. טבע יורדת כ-6.3% אף שתרופות כרגע פטורות מהמכסים החדשים שהטיל טראמפ. מניות הבנקים מאבדות גם הן שיעורים ניכרים: בנק הפועלים ובנק לאומי יורדים שניהם סביב 4.7% ומזרחי טפחות משיל כ-2.7%.
"הבורסה בתל אביב מגיבה לאירוע חיצוני, בניגוד למשברים פנימיים שידענו בשנים האחרונות", מסר הבוקר יניב פגוט, סמנכ"ל המסחר בבורסה. "ההשפעה ניכרת בעיקר דרך מניות דואליות וירידה בתיאבון הסיכון. מי שסבור שמדובר באירוע מתמשך עם השלכות מיתון עולמיות, יבחר לשנות את תיק ההשקעות שלו.
"חשוב לזכור שמדובר בהחלטות של הנשיא טראמפ שהוא יכול להפוך במהירות – במיוחד בעידן בו אמירה אחת של מנהיג עשויה לשנות את כיוון השווקים. אם תתפתח מלחמת סחר כוללת, נצפה לעוד תגובות – בעיקר מהצד האירופי. בטווח הקצר נראה עלייה במחירים, קושי בהפחתת ריבית, ולחצים פוליטיים להמשך התמריצים".  
    """

    prompt2 = " תכתוב לי סיפור של 1000 מילים בסגנון דיסני"
    prompt3 = "תסביר בפירוט את שיטת הממשל הישראלית"
    prompt4 = "תסביר בפירוט רב על אירועים ממלחמת העולם השנייה"
    prompt5 = "תפרט ככל הניתן על תולדות מדינת ישראל"
    prompt6 = "הסבר בפירוט רב על תהליך ייצור בירה"
    prompt7 = "הסבר בהרחבה על המהפכה התעשייתית והשלכותיה"
    prompt8 = "הסבר בפירוט על קונספירציית הנחיתה על הירח"
    prompt9 = "פרט על קורות חייו של בנימין נתניהו"
    prompt10 = "הסבר בפירוט את ההתרחשויות בבורסה בשנה האחרונה"
    prompt11 = "תכתוב מדריך מלא מהתחלה ועד הסוף על איך לבנות אפליקציית צ'אט ריל-טיים בעזרת React ו-Firebase, כולל קוד ודוגמאות"
    prompt12 = "תסביר בפירוט, שלב אחר שלב, את ההיסטוריה של מדינת ישראל מ-1948 ועד היום, תוך הדגשת האירועים הביטחוניים, הכלכליים והפוליטיים המרכזיים"
    prompt13 = "תרחיב על כל סוגי ה-regularization בלמידת מכונה, כולל נוסחאות, דוגמאות קוד, ויתרונות וחסרונות"
    prompt14 = "תכתוב תסריט קולנועי מלא לז'אנר מדע בדיוני, באורך של לפחות 100 מילים, כולל תיאורי דמויות, דיאלוגים, ומבנה עלילתי"
    prompt15 = "תסביר בצורה מקיפה איך פועלת מערכת המשפט בישראל, כולל הסברים על כל הערכאות, סמכויות, סוגי תביעות, ותהליכים"
    prompt16 = "בנה לי קורס בן 10 פרקים על פילוסופיה מערבית, כולל תקצירים, שאלות חזרה ודיונים לכל פרק"
    prompt17 = "תכתוב ניתוח עומק על כל שלב ושלב בתהליך הבחירות בארה״ב, כולל חוקים, שחקנים מרכזיים, דוגמאות היסטוריות והשפעות על הדמוקרטיה"
    prompt18 = "תפרט לי איך מקימים עסק אינטרנטי מאפס כולל כל הצעדים הבירוקרטיים, כלים טכנולוגיים, שיווק, אסטרטגיה ותמחור"

    prompt19 = """
    גורם מדיני על הדיווח על "פריצת דרך במו"מ": "לא מדויק. טרם הושגה הסכמה"
הגורם התייחס לדיווח על ההתקדמות במגעים להפסקת אש ושחרור חטופים, וטען: "לעת עתה לא הושגה הסכמה" • במסגרת הדיווחים, נטען כי הייתה "התקדמות של ממש" בשיחות בקהיר והושגה הסכמה על "נקודות מהותיות" • הודעת הגורם: אחרי ששלל אפשרות להפסקת אש שתימשך חמש שנים.
גורם מדיני הגיב הבוקר (שלישי) על "הדיווחים בתקשורת הזרה" וטען כי הם "אינם מדויקים". לפי הגורם המדיני, "ישראל פועלת באופן מתמשך וללא הרף מול האמריקנים והמתווכות במטרה לקדם עסקה לשחרור חטופינו, אך לעת עתה לא הושגה הסכמה". 

כאמור, אמש דווח ברויטרס על "פריצת דרך" במגעים להפסקת אש ושחרור חטופים. מקורות מצריים דיווחו על "התקדמות של ממש" בשיחות בקהיר, וטענו כי הושגה הסכמה על נקודות מהותיות, כולל הפסקת אש ארוכת-טווח. עוד דווח כי הסירוב של חמאס להתפרק מנשק נותר מוקד מחלוקת מרכזי. 

הודעת הגורם המדיני מצטרפת להודעה נוספת שמסר גורם מדיני אתמול שבה הוא שלל אפשרות להפסקת אש שתימשך חמש שנים. בהמשך, השר לעניינים אסטרטגיים רון דרמר שמשמש כראש צוות המו"מ, לא התייחס לדיווח על פריצה קרובה במגעים לעסקה, ואף העריך כי המלחמה תסתיים בניצחון בעוד שנה. בנאומו אמש בכנס JNS בירושלים הוא חזר על המחויבות לשתי מטרות המלחמה: השמדת חמאס והחזרת כל החטופים. 

עוד לפני כן, נערכו דיונים במערכת הביטחון לקראת אפשרות של הרחבת התמרון, וגיוס מילואים נרחב שצפוי בקרוב - וזה על רקע חוסר ההתקדמות במשא ומתן להפסקת אש ולהחזרת החטופים משבי חמאס. הצעד נועד ללחוץ עוד על חמאס להסכים לעסקת חטופים, ואם לא, להביא להכרעת ארגון הטרור. 

ואכן, כחלק מהרחבת התמרון, פרסמנו הבוקר לראשונה כי צה"ל פתח במבצע לחישוף צפון הרצועה. הצבא שרף שדות וחשף פירים שבהם אורבים המחבלים על רקע ההיתקלויות האחרונות בעזה. גורם בצה"ל אמר כי המטרה היא לנקות את השטחים שמאיימים על ביטחון תושבי העוטף.

דוח רפואי מתריע: סכנה ממשית שלא ניתן יהיה לאתר חטופים חללים ולהשיבם לקבורה
הדוח מעלה חשש כי מיקומם של רבים מהחטופים-החללים ידוע רק ליחידים אשר עלולים להיהרג או להעלם במהלך הקרבות, מבלי שהותירו תיעוד מסודר • בנוסף קיים סיכון לפגיעה בשלמות החללים בשל תנאי השטח בעזה • פרופ' חגי לוין, ראש מערך הבריאות של המטה: "חזרת החטופים היא תנאי יסוד לריפוי הפצע האישי, החברתי והלאומי, זוהי מחויבות מדינת ישראל כלפי אזרחיה"
דוח רפואי מיוחד, שהתפרסם היום (שלישי) מתריע מפני סכנת היעלמות מוחלטת של החטופים החללים באופן שלא ניתן יהיה לאתר את גופותיהם ולהשיבם לקבורה. מחברי המסמך קראו לפעול בדחיפות על מנת להשיב את כל 59 החטופים, בהם 35 חטופים-חללים.

מערך הבריאות במטה המשפחות להחזרת החטופים פרסם כי קיים חשש ממשי שהחללים, אזרחים וחיילים שנשבו בעזה ייעלמו. הדוח סוקר שני ממדי סיכון - אובדן מידע ופגיעה בשלמות החללים. 
מיקומם של חטופים-חללים רבים ידוע ככל הנראה למספר מועט של אנשים. קיים חשש שאותם יחידים יהרגו או ייעלמו במהלך הקרבות, מבלי שהותירו תיעוד מסודר. בכך עלול להיווצר פער ואובדן מידע. סיכון נוסף, מלבד הפערים המודיעיניים הוא פגיעה בשלמות החללים בעקבות תנאים סביבתיים. תנאי השטח בעזה עלולים לפגוע בשלמות השרידים ומקשים על זיהויים והבנת נסיבות מותם בחקירה עתידית. 

ממטה המשפחות נמסר: "נייר העמדה מתריע כי הזמן החולף שוחק עדויות, מוחק ממצאים ומערער את הסיכוי להשבתם ובכך גם ביכולת לאפשר הליך שיקום אישי ולאומי. מחברי המסמך קוראים לפעול בדחיפות על מנת להשיב את כל 59 החטופים, בהם 35 חטופים-חללים".
פרופ' חגי לוין, ראש מערך הבריאות במטה המשפחות להחזרת החטופים: "ישנה סכנה ממשית לחטופים החללים, כזו שעלולה לפגוע ביכולת להשיב אותם לקבורה ראויה. החזרת החטופים החללים לקבורה בכבוד והשבת החיים לשיקום הן תנאי יסוד לריפוי הפצע האישי, החברתי והלאומי, זוהי מחויבות מוסרית ולאומית של מדינת ישראל כלפי אזרחיה, חלק מהחוזה הבלתי כתוב שעליו נשענת החברה הישראלית".

"ללא החזרת החטופים-החללים ובהעדר ודאות, בני המשפחות הופכים להיות לחיים-מתים, והחללים נשארים מתים-חיים. פצע זה מערער את האמון שעליו בנוי המרקם החברתי כולו", הוסיף פרופ' לוין.


    """
    
    prompts = [prompt1, prompt2, prompt3, prompt4, prompt5, prompt6, prompt7, prompt8, prompt9, prompt10, 
              prompt11, prompt12, prompt13, prompt14, prompt15, prompt16, prompt17, prompt18]


    with open(f"/workspace/{file_name}.txt", "a") as f:
        f.write("#############################################################\n")
        f.write(f"### Model: {model_id}, Users: {num_users} ###\n")
        f.write("#############################################################\n")

    
    with ThreadPoolExecutor(max_workers=max_concurrent) as executor:
        start_time = time.time()
        futures = [
            executor.submit(stream_chat, prompts, i)
            for i in range(num_users)
        ]
        for future in as_completed(futures):
            future.result()

    print("All threads done.")

    plot_durations(times, tokens)



##### OUTPUT #####
# Average duration for 25 users, 25 simultaneously:: 18.264965410232545
# Average T/s for 25 users, 25 simultaneously: 27.103254174391413
